"""Report generation: Event Cards / Trending â†’ DingTalk Markdown via LLM."""

from __future__ import annotations

import json
import logging
from pathlib import Path

import jieba

from ..schemas import EventCard, TrendingItem
from .llm_client import LLMClient

logger = logging.getLogger(__name__)

PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent


class ReportWriter:
    """Generate final DingTalk Markdown reports using LLM fallback chain."""

    def __init__(self, llm_client: LLMClient):
        self.llm = llm_client

    # Format instructions appended to system_prompt to reduce user_prompt tokens
    FORMAT_INSTRUCTIONS = """

## è¾“å‡ºæ ¼å¼

æ¿å—é¡ºåºï¼šä»Šæ—¥æ ¸å¿ƒåˆ¤æ–­ â†’ ğŸ”¥ é‡å¤§å‘å¸ƒä¸äº§å“ â†’ ğŸ”¬ æŠ€æœ¯ä¸ç ”ç©¶ â†’ ğŸ’° èèµ„ä¸å¸‚åœº â†’ ğŸ”§ èŠ¯ç‰‡ä¸ç®—åŠ› â†’ âš¡ é€Ÿè§ˆ â†’ ğŸ’¡ ä¸“å®¶è§†è§’

**æ ¸å¿ƒåˆ¤æ–­**ï¼šä¸€æ®µè¯ï¼Œè¶‹åŠ¿æ´å¯Ÿï¼Œä¸å¤è¿°æ–°é—»

**æ–°é—»æ¿å—**æ¯æ¡ä¸‰å±‚ï¼š
emoji **æ ‡é¢˜** (MM-DD HH:MM UTC)
> â‰¤30å­—è¦ç‚¹
2-3å¥åˆ†æ

emojiè§„åˆ™ï¼šğŸ”´ä»…é™2-3ä¸ªæœ€é‡ç£…äº‹ä»¶ï¼Œå…¶ä½™ç”¨ğŸš€äº§å“/ğŸ”¬ç ”ç©¶/ğŸ’°èèµ„/ğŸ”§èŠ¯ç‰‡/ğŸ¤åˆä½œ/ğŸŒå¼€æº/ğŸ“œæ”¿ç­–/ğŸ“Šå¸‚åœº
æ— ç²¾ç¡®æ—¶é—´æ ‡(MM-DD)

**âš¡ é€Ÿè§ˆ**ï¼šæ¬¡è¦æ¶ˆæ¯ï¼Œæ¯æ¡â€¢ emojiä¸€å¥è¯

**ğŸ’¡ ä¸“å®¶è§†è§’**å››å—ï¼š
ğŸ”¥ä»Šæ—¥çƒ­è®®ï¼š2-3ä¸»é¢˜ï¼Œä¸»é¢˜â†’åˆ†æ­§/å…±è¯†â†’ä»£è¡¨è§‚ç‚¹(@å æ—¶é—´)
ğŸ’¬ç‹¬åˆ°æ´å¯Ÿï¼š3-5æ¡ï¼Œ@å(æ—¶é—´)ï¼š"è½¬è¿°"
ğŸ› æŠ€æœ¯åé¦ˆï¼šæ¨¡å‹/å·¥å…·ä½“éªŒï¼ŒåŒäº§å“èšåˆï¼Œæ­£é¢+åæ§½
ğŸ“Šç¤¾åŒºæƒ…ç»ªï¼š1å¥è¯

**åˆ†æµè§„åˆ™**ï¼šopinionâ†’ä¸“å®¶è§†è§’ï¼Œnewsâ†’æŒ‰categoryåˆ†å…¥æ–°é—»æ¿å—
**æ ¼å¼é™åˆ¶**ï¼šé’‰é’‰Markdownï¼Œä»…ç”¨#/**/>/-/[](url)ï¼Œç¦ç”¨è¡¨æ ¼/ä»£ç å—/åˆ é™¤çº¿/åˆ†å‰²çº¿"""

    def generate_twitter_report(
        self,
        events: list[EventCard],
        prompt_file: str,
        date_str: str,
    ) -> str:
        """Generate report from Event Cards (global / china pipeline)."""
        base_system, _ = self._load_prompt(prompt_file)
        system_prompt = base_system + self.FORMAT_INSTRUCTIONS

        def _format_event(e: EventCard) -> str:
            time_str = (
                e.event_time.strftime("%m-%d %H:%M UTC")
                if e.event_time
                else "æœªçŸ¥"
            )
            sources_str = ", ".join(
                f"@{s.author.lstrip('@')}" for s in e.sources
            ) if e.sources else "æ— "
            key_facts_str = "; ".join(e.key_facts) if e.key_facts else "æ— "

            return (
                f"{e.title} | ç±»åˆ«: {e.category.value} | "
                f"é‡è¦æ€§: {e.importance} | ç±»å‹: {e.event_type} | "
                f"æ—¶é—´: {time_str}\n"
                f"å…³é”®äº‹å®: {key_facts_str}\n"
                f"åˆ†æå¸ˆè§†è§’: {e.analyst_angle}\n"
                f"æ¥æºæ¨æ–‡: {sources_str}"
            )

        events_text = "\n\n".join(
            _format_event(e) for e in events
        )

        user_prompt = f"""æ—¥æœŸï¼š{date_str}
ä»¥ä¸‹æ˜¯ä»Šæ—¥ {len(events)} ä¸ªäº‹ä»¶ï¼š

{events_text}"""

        return self.llm.generate(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            temperature=0.5,
            max_tokens=8192,
        )

    def generate_merged_china_report(
        self,
        twitter_events: list[EventCard],
        trending_items: list[TrendingItem],
        prompt_file: str,
        date_str: str,
    ) -> str:
        """Generate merged china_ai report: Twitter report as-is + deduplicated trending appended."""

        # 1. Use the original method to generate the full Twitter report (untouched)
        twitter_report = self.generate_twitter_report(twitter_events, prompt_file, date_str)

        # 2. Deduplicate trending against Twitter events
        unique_trending = self._deduplicate_trending(twitter_events, trending_items)

        if not unique_trending:
            logger.info("All trending items duplicated with Twitter events, skipping trending section")
            return twitter_report

        # 3. Format deduplicated trending and append to Twitter report
        lines: list[str] = [
            "",
            "## ğŸ‡¨ğŸ‡³ å›½å†…çƒ­æœé€Ÿé€’",
            "",
            "> ä»¥ä¸‹ä¸ºå›½å†…ç§‘æŠ€åª’ä½“åŠç¤¾äº¤å¹³å°çƒ­è®®è¯é¢˜ï¼Œä¸ä¸Šæ–¹ Twitter ä¿¡æºäº’è¡¥ã€‚",
            "",
        ]

        for te in unique_trending:
            src = f"ï¼ˆ{te.platform} Top {te.rank}ï¼‰" if te.platform and te.rank else ""
            lines.append(f"- ğŸ”¥ **{te.title}**{src}")

        lines.append("")
        lines.append("---")

        trending_section = "\n".join(lines)

        logger.info(
            "Merged report: Twitter report + %d/%d unique trending items",
            len(unique_trending), len(trending_items),
        )
        return twitter_report.rstrip() + "\n" + trending_section + "\n"

    # ä¸å‚ä¸å»é‡æ¯”è¾ƒçš„é«˜é¢‘è¯/åœç”¨è¯
    _DEDUP_STOPWORDS = {
        "çš„", "äº†", "åœ¨", "æ˜¯", "å’Œ", "ä¸", "å¯¹", "äº", "å°†", "ä¸º", "è¢«",
        "AI", "äººå·¥æ™ºèƒ½", "å¤§æ¨¡å‹", "LLM", "å‘å¸ƒ", "å®£å¸ƒ", "æ¨å‡º",
        "è¡¨ç¤º", "ç§°", "è¯´", "æŒ‡å‡º", "è®¤ä¸º",
    }

    @staticmethod
    def _extract_keywords(text: str) -> set[str]:
        """æå–æ–‡æœ¬ä¸­é•¿åº¦â‰¥2çš„å®è´¨è¯ï¼ˆå»æ‰åœç”¨è¯ï¼‰ã€‚"""
        words = jieba.cut(text)
        return {
            w for w in words
            if len(w) >= 2 and w not in ReportWriter._DEDUP_STOPWORDS
        }

    def _deduplicate_trending(
        self,
        twitter_events: list[EventCard],
        trending_items: list[TrendingItem],
    ) -> list[TrendingItem]:
        """çƒ­æœå»é‡ï¼šè‹¥çƒ­æœæ¡ç›®ä¸ä»»æ„ Twitter äº‹ä»¶å…±äº« â‰¥2 ä¸ªå®è´¨è¯ï¼Œè§†ä¸ºé‡å¤ã€‚"""
        if not trending_items:
            return []

        # é¢„è®¡ç®— Twitter äº‹ä»¶å…³é”®è¯é›†åˆ
        event_kw_list: list[set[str]] = []
        for e in twitter_events:
            event_kw_list.append(self._extract_keywords(e.title))

        unique: list[TrendingItem] = []
        for te in trending_items:
            te_kw = self._extract_keywords(te.title)
            is_dup = False
            for ev_kw in event_kw_list:
                if len(te_kw & ev_kw) >= 2:
                    is_dup = True
                    break
            if not is_dup:
                unique.append(te)

        logger.info(
            "çƒ­æœå»é‡ï¼šåŸå§‹ %d æ¡ï¼Œå»é‡åä¿ç•™ %d æ¡ï¼ˆç§»é™¤ %d æ¡é‡å¤ï¼‰",
            len(trending_items), len(unique),
            len(trending_items) - len(unique),
        )
        return unique

    def generate_trending_report(
        self,
        items: list[TrendingItem],
        prompt_file: str,
        date_str: str,
    ) -> str:
        """Generate report from trending items (trending pipeline)."""
        system_prompt, one_shot = self._load_prompt(prompt_file)

        items_text = "\n".join(
            f"- [{item.platform}] {item.title} (çƒ­åº¦æ’å: {item.rank})"
            for item in items
        )

        user_prompt = f"""ä»¥ä¸‹æ˜¯ä¸€ä»½é«˜è´¨é‡çƒ­æœé€Ÿé€’èŒƒä¾‹ï¼Œè¯·ä¸¥æ ¼å­¦ä¹ å…¶é£æ ¼å’Œç»“æ„ï¼š

{one_shot}

---

ç°åœ¨ï¼Œè¯·åŸºäºä»¥ä¸‹ä»Šæ—¥çƒ­æœæ•°æ®ï¼ˆ{len(items)} æ¡ï¼‰ï¼Œç”ŸæˆåŒæ ·é£æ ¼çš„çƒ­æœé€Ÿé€’ã€‚
æ—¥æœŸï¼š{date_str}

{items_text}"""

        return self.llm.generate(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            temperature=0.5,
            max_tokens=4096,
        )

    @staticmethod
    def _load_prompt(prompt_file: str) -> tuple[str, str]:
        """Load prompt file, split into system prompt and one-shot example.

        Expected format:
        ---SYSTEM---
        <system prompt>
        ---ONESHOT---
        <one-shot example>
        """
        path = PROJECT_ROOT / prompt_file
        content = path.read_text(encoding="utf-8")

        if "---SYSTEM---" in content and "---ONESHOT---" in content:
            parts = content.split("---ONESHOT---", 1)
            system_part = parts[0].replace("---SYSTEM---", "").strip()
            one_shot = parts[1].strip()
            return system_part, one_shot

        # Fallback: entire file is one-shot, use default system prompt
        default_system = (
            "ä½ æ˜¯ã€Œé˜¿é‡Œäº‘å‡ºæµ·Â·å…¨çƒ AI è¡Œä¸šæƒ…æŠ¥åˆ†æå¸ˆã€ï¼Œ"
            "æ¯æ—¥ä¸ºæŠ€æœ¯å†³ç­–è€…å’ŒæŠ•èµ„å›¢é˜Ÿç”Ÿæˆ AI è¡Œä¸šæ—¥æŠ¥ã€‚"
        )
        return default_system, content
