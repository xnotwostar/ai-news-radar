"""Report generation: Event Cards / Trending â†’ DingTalk Markdown via LLM."""

from __future__ import annotations

import json
import logging
from pathlib import Path

import jieba

from ..schemas import EventCard, TrendingItem
from .llm_client import LLMClient

logger = logging.getLogger(__name__)

PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent


class ReportWriter:
    """Generate final DingTalk Markdown reports using LLM fallback chain."""

    def __init__(self, llm_client: LLMClient):
        self.llm = llm_client

    # Format instructions appended to system_prompt to reduce user_prompt tokens
    FORMAT_INSTRUCTIONS = """

## è¾“å‡ºæ ¼å¼

æ¿å—é¡ºåºï¼šä»Šæ—¥æ ¸å¿ƒåˆ¤æ–­ â†’ ğŸ”¥ é‡å¤§å‘å¸ƒä¸äº§å“ â†’ ğŸ”¬ æŠ€æœ¯ä¸ç ”ç©¶ â†’ ğŸ’° èèµ„ä¸å¸‚åœº â†’ ğŸ”§ èŠ¯ç‰‡ä¸ç®—åŠ› â†’ âš¡ é€Ÿè§ˆ â†’ ğŸ’¡ ä¸“å®¶è§†è§’

**æ ¸å¿ƒåˆ¤æ–­**ï¼šä¸€æ®µè¯ï¼Œè¶‹åŠ¿æ´å¯Ÿï¼Œä¸å¤è¿°æ–°é—»

**æ–°é—»æ¿å—**æ¯æ¡ä¸‰å±‚ï¼š
emoji [**æ ‡é¢˜**](æ¥æºæ¨æ–‡URL)
> â‰¤30å­—è¦ç‚¹
2-3å¥åˆ†æ

emojiè§„åˆ™ï¼šğŸ”´ä»…é™2-3ä¸ªæœ€é‡ç£…äº‹ä»¶ï¼Œå…¶ä½™ç”¨ğŸš€äº§å“/ğŸ”¬ç ”ç©¶/ğŸ’°èèµ„/ğŸ”§èŠ¯ç‰‡/ğŸ¤åˆä½œ/ğŸŒå¼€æº/ğŸ“œæ”¿ç­–/ğŸ“Šå¸‚åœº
**è¾“å‡ºæŠ¥å‘Šä¸­ä¸è¦æ˜¾ç¤ºæ—¥æœŸæ—¶é—´**ï¼ˆäº‹ä»¶æ—¶é—´ä»…ä¾›åˆ†æå‚è€ƒï¼Œä¸å‡ºç°åœ¨æ ‡é¢˜æˆ–æ­£æ–‡ä¸­ï¼‰

**âš¡ é€Ÿè§ˆ**ï¼šæ¬¡è¦æ¶ˆæ¯ï¼Œæ¯æ¡â€¢ emojiä¸€å¥è¯

**ğŸ’¡ ä¸“å®¶è§†è§’**ï¼ˆå››ä¸ªå­æ¿å—ï¼Œç”¨åŠ ç²—+emojiåšå­æ ‡é¢˜ï¼Œä¸è¦ç”¨###æ ‡é¢˜ï¼‰ï¼š

**ğŸ”¥ ä»Šæ—¥çƒ­è®®ç„¦ç‚¹**

æ¯ä¸ªçƒ­è®®ä¸»é¢˜ç”¨ä»¥ä¸‹æ ¼å¼ï¼Œä¸»é¢˜ä¹‹é—´ç©ºä¸€è¡Œï¼š

**ä¸»é¢˜åç§°**
å…±è¯†ï¼šä¸€å¥è¯ | åˆ†æ­§ï¼šä¸€å¥è¯
â€” [@ä¸“å®¶å](é“¾æ¥)ï¼š"è§‚ç‚¹"
â€” [@ä¸“å®¶å](é“¾æ¥)ï¼š"è§‚ç‚¹"

**å¦ä¸€ä¸ªä¸»é¢˜åç§°**
å…±è¯†ï¼šä¸€å¥è¯
â€” [@ä¸“å®¶å](é“¾æ¥)ï¼š"è§‚ç‚¹"

---

**ğŸ’¬ ç‹¬åˆ°æ´å¯Ÿ**

æ¯æ¡ç”¨ â€” å¼€å¤´ï¼Œæ¡ç›®ä¹‹é—´ç©ºä¸€è¡Œï¼š

â€” [@ä¸“å®¶å](é“¾æ¥)ï¼š"åŸè¯æˆ–ç²¾ç‚¼è½¬è¿°"

â€” [@ä¸“å®¶å](é“¾æ¥)ï¼š"åŸè¯æˆ–ç²¾ç‚¼è½¬è¿°"

â€” [@ä¸“å®¶å](é“¾æ¥)ï¼š"åŸè¯æˆ–ç²¾ç‚¼è½¬è¿°"

ï¼ˆæœ€å¤š5æ¡ï¼Œä¸æ±‚å¤šæ±‚ç²¾ï¼‰

---

**ğŸ›  æŠ€æœ¯ä½¿ç”¨åé¦ˆ**

æ¯ä¸ªäº§å“ç”¨åŠ ç²—äº§å“åï¼Œâœ…æ­£é¢ âš ï¸åæ§½ï¼Œäº§å“ä¹‹é—´ç©ºä¸€è¡Œï¼š

**GPT-4o**
âœ… æ­£é¢åé¦ˆå†…å®¹
âš ï¸ åæ§½å†…å®¹

**Claude Sonnet 4.6**
âœ… æ­£é¢åé¦ˆå†…å®¹
âš ï¸ åæ§½å†…å®¹

---

**ğŸ“Š ä»Šæ—¥ç¤¾åŒºæƒ…ç»ª**

ä¸€æ®µè¯æ€»ç»“å³å¯ï¼Œä¸ç”¨åˆ—è¡¨ã€‚

æ ¼å¼è§„åˆ™å¼ºè°ƒï¼š
1. å­æ¿å—æ ‡é¢˜ç”¨ **åŠ ç²—+emoji** è€Œä¸æ˜¯ ### æ ‡é¢˜ï¼ˆé’‰é’‰ä¸æ”¯æŒ###ï¼‰
2. å­æ¿å—ä¹‹é—´ç”¨ --- åˆ†éš”çº¿éš”å¼€
3. ä¸è¦ç”¨ > å¼•ç”¨æ¥åšæ ‡é¢˜æˆ–ä¸»é¢˜åï¼ˆé’‰é’‰ä¼šæ¸²æŸ“æˆç°è‰²å—ï¼‰
4. çƒ­è®®ä¸»é¢˜åç”¨ **åŠ ç²—** è€Œä¸æ˜¯ > å¼•ç”¨
5. äº§å“åç”¨ **åŠ ç²—** è€Œä¸æ˜¯ > å¼•ç”¨
6. ä¸“å®¶å¼•ç”¨ç»Ÿä¸€ç”¨ â€” å¼€å¤´ï¼ˆç ´æŠ˜å·ï¼‰ï¼Œä¸ç”¨ - æˆ– â€¢
7. æ‰€æœ‰ @ä¸“å®¶å å¿…é¡»å¸¦è¶…é“¾æ¥ [@å](https://x.com/å)

**åˆ†æµè§„åˆ™**ï¼šopinionâ†’ä¸“å®¶è§†è§’ï¼Œnewsâ†’æŒ‰categoryåˆ†å…¥æ–°é—»æ¿å—
**æ ¼å¼é™åˆ¶**ï¼šé’‰é’‰Markdownï¼Œä»…ç”¨#/**/>/-/[](url)ï¼Œç¦ç”¨è¡¨æ ¼/ä»£ç å—/åˆ é™¤çº¿/åˆ†å‰²çº¿

**é“¾æ¥è§„åˆ™ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰**ï¼š
- æ¯æ¡æ–°é—»çš„æ ‡é¢˜æœ¬èº«å°±æ˜¯è¶…é“¾æ¥ï¼Œæ ¼å¼ï¼šemoji [**æ ‡é¢˜**](æ¥æºæ¨æ–‡URL)
- æ¥æºæ¨æ–‡æ•°æ®ä¸­æ¯ä½ä½œè€…éƒ½é™„å¸¦äº†å®Œæ•´URLï¼ˆå¦‚ https://x.com/author/status/123456ï¼‰ï¼Œç›´æ¥ä½¿ç”¨
- å¦‚æœæ¥æºæœ‰å¤šä¸ªä½œè€…ï¼Œæ ‡é¢˜é“¾æ¥ä½¿ç”¨engagementæœ€é«˜çš„é‚£æ¡URL
- ä¸“å®¶è§†è§’ä¸­çš„@åä¹Ÿå¿…é¡»æ˜¯è¶…é“¾æ¥ï¼š[@ä¸“å®¶å](https://x.com/ä¸“å®¶å)ï¼š"è§‚ç‚¹"
- é€Ÿè§ˆä¸­çš„æ¯æ¡ä¹Ÿè¦å¸¦é“¾æ¥ï¼šâ€¢ emoji [ä¸€å¥è¯æ‘˜è¦](URL)
- ç¤ºä¾‹ï¼šğŸš€ [**OpenAIå‘å¸ƒGPT-5**](https://x.com/OpenAI/status/123456)
- æ¥æºå¦‚æœæ˜¯ç§‘æŠ€åª’ä½“åç§°ï¼ˆTechCrunchã€The Vergeã€VentureBeat ç­‰ï¼‰ï¼Œç”¨ [åª’ä½“å](URL) æ ¼å¼é™„åŸæ–‡é“¾æ¥ï¼Œä¸ç”¨ @ æ ¼å¼
- Twitter æ¥æºç»§ç»­ç”¨ [@ç”¨æˆ·å](URL) æ ¼å¼
- åŒä¸€äº‹ä»¶å¦‚æœåŒæ—¶æœ‰ Twitter å’Œåª’ä½“æ¥æºï¼Œéƒ½åˆ—å‡ºæ¥"""

    def generate_twitter_report(
        self,
        events: list[EventCard],
        prompt_file: str,
        date_str: str,
    ) -> str:
        """Generate report from Event Cards (global / china pipeline)."""
        base_system, _ = self._load_prompt(prompt_file)
        system_prompt = base_system + self.FORMAT_INSTRUCTIONS

        def _format_event(e: EventCard) -> str:
            def _fmt_source(s):
                # RSS sources: use media name; Twitter: use @handle
                if s.url and not s.url.startswith("https://x.com/"):
                    return f"{s.author} ({s.url})"
                return f"@{s.author.lstrip('@')} ({s.url})" if s.url else f"@{s.author.lstrip('@')}"

            sources_str = ", ".join(
                _fmt_source(s) for s in e.sources
            ) if e.sources else "æ— "
            key_facts_str = "; ".join(e.key_facts) if e.key_facts else "æ— "

            return (
                f"{e.title} | ç±»åˆ«: {e.category.value} | "
                f"é‡è¦æ€§: {e.importance} | ç±»å‹: {e.event_type}\n"
                f"å…³é”®äº‹å®: {key_facts_str}\n"
                f"åˆ†æå¸ˆè§†è§’: {e.analyst_angle}\n"
                f"æ¥æºæ¨æ–‡: {sources_str}"
            )

        # Limit to top 25 events by importance to avoid prompt token overflow
        MAX_EVENTS = 25
        if len(events) > MAX_EVENTS:
            logger.info("Trimming events from %d to %d (by importance)", len(events), MAX_EVENTS)
            events = sorted(events, key=lambda e: e.importance, reverse=True)[:MAX_EVENTS]

        events_text = "\n\n".join(
            _format_event(e) for e in events
        )

        user_prompt = f"""æ—¥æœŸï¼š{date_str}
ä»¥ä¸‹æ˜¯ä»Šæ—¥ {len(events)} ä¸ªäº‹ä»¶ï¼š

{events_text}"""

        return self.llm.generate(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            temperature=0.5,
            max_tokens=8192,
        )

    def generate_merged_china_report(
        self,
        twitter_events: list[EventCard],
        trending_items: list[TrendingItem],
        prompt_file: str,
        date_str: str,
    ) -> str:
        """Generate merged china_ai report: Twitter report as-is + deduplicated trending appended."""

        # 1. Use the original method to generate the full Twitter report (untouched)
        twitter_report = self.generate_twitter_report(twitter_events, prompt_file, date_str)

        # 2. Deduplicate trending against Twitter events
        unique_trending = self._deduplicate_trending(twitter_events, trending_items)

        if not unique_trending:
            logger.info("All trending items duplicated with Twitter events, skipping trending section")
            return twitter_report

        # 3. Format deduplicated trending and append to Twitter report
        lines: list[str] = [
            "",
            "## ğŸ‡¨ğŸ‡³ å›½å†…çƒ­æœé€Ÿé€’",
            "",
            "> ä»¥ä¸‹ä¸ºå›½å†…ç§‘æŠ€åª’ä½“åŠç¤¾äº¤å¹³å°çƒ­è®®è¯é¢˜ï¼Œä¸ä¸Šæ–¹ Twitter ä¿¡æºäº’è¡¥ã€‚",
            "",
        ]

        for te in unique_trending:
            src = f"ï¼ˆ{te.platform} Top {te.rank}ï¼‰" if te.platform and te.rank else ""
            lines.append(f"- ğŸ”¥ **{te.title}**{src}")

        lines.append("")
        lines.append("---")

        trending_section = "\n".join(lines)

        logger.info(
            "Merged report: Twitter report + %d/%d unique trending items",
            len(unique_trending), len(trending_items),
        )
        return twitter_report.rstrip() + "\n" + trending_section + "\n"

    # ä¸å‚ä¸å»é‡æ¯”è¾ƒçš„é«˜é¢‘è¯/åœç”¨è¯
    _DEDUP_STOPWORDS = {
        "çš„", "äº†", "åœ¨", "æ˜¯", "å’Œ", "ä¸", "å¯¹", "äº", "å°†", "ä¸º", "è¢«",
        "AI", "äººå·¥æ™ºèƒ½", "å¤§æ¨¡å‹", "LLM", "å‘å¸ƒ", "å®£å¸ƒ", "æ¨å‡º",
        "è¡¨ç¤º", "ç§°", "è¯´", "æŒ‡å‡º", "è®¤ä¸º",
    }

    @staticmethod
    def _extract_keywords(text: str) -> set[str]:
        """æå–æ–‡æœ¬ä¸­é•¿åº¦â‰¥2çš„å®è´¨è¯ï¼ˆå»æ‰åœç”¨è¯ï¼‰ã€‚"""
        words = jieba.cut(text)
        return {
            w for w in words
            if len(w) >= 2 and w not in ReportWriter._DEDUP_STOPWORDS
        }

    def _deduplicate_trending(
        self,
        twitter_events: list[EventCard],
        trending_items: list[TrendingItem],
    ) -> list[TrendingItem]:
        """çƒ­æœå»é‡ï¼šè‹¥çƒ­æœæ¡ç›®ä¸ä»»æ„ Twitter äº‹ä»¶å…±äº« â‰¥2 ä¸ªå®è´¨è¯ï¼Œè§†ä¸ºé‡å¤ã€‚"""
        if not trending_items:
            return []

        # é¢„è®¡ç®— Twitter äº‹ä»¶å…³é”®è¯é›†åˆ
        event_kw_list: list[set[str]] = []
        for e in twitter_events:
            event_kw_list.append(self._extract_keywords(e.title))

        unique: list[TrendingItem] = []
        for te in trending_items:
            te_kw = self._extract_keywords(te.title)
            is_dup = False
            for ev_kw in event_kw_list:
                if len(te_kw & ev_kw) >= 2:
                    is_dup = True
                    break
            if not is_dup:
                unique.append(te)

        logger.info(
            "çƒ­æœå»é‡ï¼šåŸå§‹ %d æ¡ï¼Œå»é‡åä¿ç•™ %d æ¡ï¼ˆç§»é™¤ %d æ¡é‡å¤ï¼‰",
            len(trending_items), len(unique),
            len(trending_items) - len(unique),
        )
        return unique

    @staticmethod
    def _load_prompt(prompt_file: str) -> tuple[str, str]:
        """Load prompt file, split into system prompt and one-shot example.

        Expected format:
        ---SYSTEM---
        <system prompt>
        ---ONESHOT---
        <one-shot example>
        """
        path = PROJECT_ROOT / prompt_file
        content = path.read_text(encoding="utf-8")

        if "---SYSTEM---" in content and "---ONESHOT---" in content:
            parts = content.split("---ONESHOT---", 1)
            system_part = parts[0].replace("---SYSTEM---", "").strip()
            one_shot = parts[1].strip()
            return system_part, one_shot

        # Fallback: entire file is one-shot, use default system prompt
        default_system = (
            "ä½ æ˜¯ã€Œé˜¿é‡Œäº‘å‡ºæµ·Â·å…¨çƒ AI è¡Œä¸šæƒ…æŠ¥åˆ†æå¸ˆã€ï¼Œ"
            "æ¯æ—¥ä¸ºæŠ€æœ¯å†³ç­–è€…å’ŒæŠ•èµ„å›¢é˜Ÿç”Ÿæˆ AI è¡Œä¸šæ—¥æŠ¥ã€‚"
        )
        return default_system, content
